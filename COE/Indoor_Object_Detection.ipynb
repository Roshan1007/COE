{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ae00bb-dd84-437a-b0e0-afbe6e480ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov7' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    " ! git clone https://github.com/WongKinYiu/yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cdb51f-fa9e-4f66-9646-3e511948ed96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\tut\\Indoor object detection\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4109485e-6736-42d1-8b84-02ba0615cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d7267-45ff-4960-a52c-d2c2106f9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from yolov7.models.yolo import Model\n",
    "from yolov7.utils.datasets import create_dataloader\n",
    "from yolov7.utils.general import check_img_size, increment_path\n",
    "from yolov7.utils.loss import ComputeLoss\n",
    "from yolov7.utils.torch_utils import select_device, train_one_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b05b9-c98e-4df4-a656-497b42c23c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and device\n",
    "data_yaml_path = 'C:/Users/HP/Desktop/data/data.yaml'\n",
    "weights_path = 'C:/Users/HP/Desktop/data/data/yolov7.pt'  # Pre-trained weights\n",
    "device = select_device('0')  # '0' for GPU, '' for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96dfc31-7330-41b6-b620-301a336b7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset information\n",
    "with open(data_yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323da4b5-3ef7-4609-b902-ee5f3a492229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "nc = data['nc']  # Number of classes\n",
    "img_size = 640   # Image size (can be adjusted)\n",
    "batch_size = 16  # Batch size (adjust based on your hardware)\n",
    "epochs = 50      # Number of epochs\n",
    "hyp = {\n",
    "    'lr0': 0.01,  # Initial learning rate\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    # Add other hyperparameters as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d5472-c96b-4c2c-8cea-f3c44dac0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = Model(cfg='C:/Users/HP/Desktop/data/yolov7.yaml', nc=nc).to(device)\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device)['model'])\n",
    "model.half()  # To use mixed precision if supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a715e1-94e1-4551-b74f-148201ededac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, dataset = create_dataloader(data['train'], img_size, batch_size, 32, hyp, augment=True, cache=False, rect=False)\n",
    "val_loader = create_dataloader(data['val'], img_size, batch_size, 32, hyp, augment=False, cache=False, rect=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f5706-ec9d-4f14-9416-0a0fd9f42e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hyp['lr0'], momentum=hyp['momentum'], weight_decay=hyp['weight_decay'])\n",
    "criterion = ComputeLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a01b3-caf2-49e6-8f03-15576f2b80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for imgs, targets, paths, _ in train_loader:\n",
    "        imgs = imgs.to(device).half()\n",
    "        targets = targets.to(device)\n",
    "        preds = model(imgs)\n",
    "        loss, loss_items = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Optionally, validate the model on the validation set\n",
    "    model.eval()\n",
    "    # Validation code here...\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'model_epoch_{epoch}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d86e0-278a-447d-b6f1-c497332b178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "torch.save(model.state_dict(), 'final_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
